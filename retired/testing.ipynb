{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Project: Neural Network for MHC Peptide Prediction\n",
    "Class(s): (none) \n",
    "Function: Organizes main pipeline execution and testing \n",
    "\n",
    "Author: Patrick V. Holec\n",
    "Date Created: 2/3/2017\n",
    "Date Updated: 3/20/2017\n",
    "\n",
    "This is for actual data testing\n",
    "\n",
    "'''\n",
    "\n",
    "# standard libraries\n",
    "import time\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "# nonstandard libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current peptide: -----L-F------\n",
      "Current peptide: -E---L-F------\n",
      "Current peptide: -E-S-L-F------\n",
      "Current peptide: -E-S-L-F-----G\n",
      "Current peptide: -E-S-L-FY----G\n",
      "Current peptide: -E-STL-FY----G\n",
      "Current peptide: -E-STLAFY----G\n",
      "Current peptide: -E-STLAFY---VG\n",
      "Current peptide: -E-STLAFY--RVG\n",
      "Current peptide: -EGSTLAFY--RVG\n",
      "Current peptide: -EGSTLAFY-VRVG\n",
      "Current peptide: -EGSTLAFYAVRVG\n",
      "Current peptide: AEGSTLAFYAVRVG\n",
      "Total score: 19.8467270955\n",
      "Current peptide: ------FF------\n",
      "Current peptide: ------FF-A----\n",
      "Current peptide: -----HFF-A----\n",
      "Current peptide: -----HFF-A--V-\n",
      "Current peptide: E----HFF-A--V-\n",
      "Current peptide: E----HFFRA--V-\n",
      "Current peptide: E---LHFFRA--V-\n",
      "Current peptide: E---LHFFRA-IV-\n",
      "Current peptide: E---LHFFRAQIV-\n",
      "Current peptide: E-G-LHFFRAQIV-\n",
      "Current peptide: ENG-LHFFRAQIV-\n",
      "Current peptide: ENGRLHFFRAQIV-\n",
      "Current peptide: ENGRLHFFRAQIVG\n",
      "Total score: 24.3885638714\n",
      "Current peptide: -R-----F------\n",
      "Current peptide: AR-----F------\n",
      "Current peptide: AR-----F----P-\n",
      "Current peptide: ARP----F----P-\n",
      "Current peptide: ARP----F--Q-P-\n",
      "Current peptide: ARP----F--QTP-\n",
      "Current peptide: ARP----F--QTPW\n",
      "Current peptide: ARP----F-AQTPW\n",
      "Current peptide: ARPV---F-AQTPW\n",
      "Current peptide: ARPVV--F-AQTPW\n",
      "Current peptide: ARPVV-FF-AQTPW\n",
      "Current peptide: ARPVVIFF-AQTPW\n",
      "Current peptide: ARPVVIFFFAQTPW\n",
      "Total score: 12.6944211423\n",
      "Current peptide: -------F-----C\n",
      "Current peptide: -------F----GC\n",
      "Current peptide: -------F-S--GC\n",
      "Current peptide: -------F-S-TGC\n",
      "Current peptide: -------F-SITGC\n",
      "Current peptide: ---V---F-SITGC\n",
      "Current peptide: ---VI--F-SITGC\n",
      "Current peptide: --AVI--F-SITGC\n",
      "Current peptide: --AVI-FF-SITGC\n",
      "Current peptide: --AVI-FFRSITGC\n",
      "Current peptide: -RAVI-FFRSITGC\n",
      "Current peptide: MRAVI-FFRSITGC\n",
      "Current peptide: MRAVIHFFRSITGC\n",
      "Total score: 8.21135255694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aas = 'ACDEFGHIKLMNPQRSTVWY_'\n",
    "threshold = 3\n",
    "\n",
    "\n",
    "model_files = ['./logs/model_{}.p'.format(i) for i in xrange(10005,10009)]\n",
    "data_files = ['A12_{}-{}_seqs.txt'.format(i,i+1) for i in xrange(1,5)]\n",
    "\n",
    "weights,confidences = [],[]\n",
    "\n",
    "\n",
    "# Acquire sw/pw trained matrices\n",
    "for model_file in model_files:\n",
    "    \n",
    "    model_dict = pickle.load(open(model_file,'rb'))\n",
    "    \n",
    "    # Load layers\n",
    "    W_sw_layer = np.squeeze(model_dict['W_sw'])\n",
    "    W_pw_layer = np.squeeze(model_dict['W_pw'])\n",
    "    W_fc_layers = np.squeeze(model_dict['W_fc'])\n",
    "    b_fc_layers = np.squeeze(model_dict['b_fc'])\n",
    "    \n",
    "    # Split FC contributions\n",
    "    W_fc = np.dot(W_fc_layers[0],np.add(W_fc_layers[1],np.expand_dims(b_fc_layers[0],axis=1)))\n",
    "    W_sw_weight,W_pw_weight = np.split(W_fc,[W_sw_layer.shape[1]])\n",
    "\n",
    "    ### Manipulate into standard format ###\n",
    "    # SW Contribution\n",
    "    W_sw_weight = np.reshape(np.tile(W_sw_weight,21),(W_sw_weight.size,21)).T\n",
    "    W_sw = np.multiply(W_sw_layer,W_sw_weight)\n",
    "    # PW Contribution\n",
    "    W_pw_weight = np.reshape(np.tile(W_pw_weight,21**2),(W_pw_weight.size,21**2)).T\n",
    "    W_pw_weight = np.reshape(W_pw_weight,(21,21,W_pw_weight.shape[1]))\n",
    "    W_pw = np.multiply(W_pw_layer,W_pw_weight)\n",
    "    \n",
    "    weights.append((W_sw,W_pw))\n",
    "\n",
    "    \n",
    "# Solve for sw/pw contributions\n",
    "for data_file in data_files:\n",
    "    \n",
    "    with open(data_file,'r') as f:\n",
    "        content = f.readlines()\n",
    "    sequences = [x.strip() for x in content[1:]] \n",
    "    sequences = [x[:x.index(',')] for x in sequences] \n",
    "        \n",
    "    # sw confidence calculations\n",
    "    sw_confidence = np.zeros(W_sw_weight.shape)\n",
    "    for i,sample in enumerate(sequences):\n",
    "        for j,char in enumerate(sample):\n",
    "            try: sw_confidence[aas.index(char),j] += 1\n",
    "            except ValueError: raw_input(aas+':'+char)\n",
    "    \n",
    "    # pw confidence calculations\n",
    "    pw_confidence = np.zeros(W_pw_weight.shape)\n",
    "    for i,sample in enumerate(sequences):\n",
    "        pair_index = 0\n",
    "        for j,char1 in enumerate(sample):\n",
    "            for k,char2 in enumerate(sample[j+1:]):\n",
    "                pw_confidence[aas.index(char1),aas.index(char2),pair_index] += 1\n",
    "                pair_index += 1\n",
    "                \n",
    "    confidences.append((sw_confidence,pw_confidence))\n",
    "\n",
    "    \n",
    "# Reduce the trained models to only show confident outputs\n",
    "for w,c,n in zip(weights,confidences,data_files):\n",
    "    \n",
    "    W_sw,W_pw = w\n",
    "    C_sw,C_pw = c\n",
    "    \n",
    "    # start sw processing\n",
    "    for i in xrange(W_sw.shape[0]):\n",
    "        for j in xrange(W_sw.shape[1]):\n",
    "            if C_sw[i][j] < threshold:\n",
    "                W_sw[i][j] = -np.inf\n",
    "\n",
    "    # start pw processing\n",
    "    for i in xrange(W_pw.shape[0]):\n",
    "        for j in xrange(W_pw.shape[1]):\n",
    "            for k in xrange(W_pw.shape[2]):\n",
    "                if C_pw[i][j][k] < threshold:\n",
    "                    W_pw[i][j][k] = -np.inf\n",
    "    \n",
    "    # so the plan: look for best single pair, keep building from there\n",
    "    \n",
    "    total_score = 0.\n",
    "    accepted_positions = [7]\n",
    "    accepted_residues = ['-' for i in xrange(W_sw.shape[1])]\n",
    "    accepted_residues[7] = 'F'\n",
    "    positions = list(xrange(W_sw.shape[1]))\n",
    "    \n",
    "\n",
    "    # sitewise start!\n",
    "    \n",
    "    \n",
    "    # iterative additions\n",
    "    while len(positions) > len(accepted_positions):\n",
    "        \n",
    "        pair_dict = {}\n",
    "                \n",
    "        pair_index = 0\n",
    "        for i in xrange(W_sw.shape[1]): # ind1\n",
    "            for j in xrange(i+1,W_sw.shape[1]): # ind2\n",
    "                if (i in accepted_positions) != (j in accepted_positions): #exclusive or\n",
    "                    \n",
    "                    if i in accepted_positions:\n",
    "                        k = aas.index(accepted_residues[i])\n",
    "                        for l in xrange(W_pw.shape[0]):\n",
    "                            pair_dict[(i,aas[k],j,aas[l])] = W_sw[l][j]\n",
    "                            for p in accepted_positions:\n",
    "                                pair_dict[(i,aas[k],j,aas[l])] += W_pw[k][l][pair_index]  \n",
    "                    \n",
    "                    elif j in accepted_positions:\n",
    "                        l = aas.index(accepted_residues[j])\n",
    "                        for k in xrange(W_pw.shape[0]): # aa1\n",
    "                            pair_dict[(i,aas[k],j,aas[l])] = W_sw[k][i]\n",
    "                            for p in accepted_positions:\n",
    "                                pair_dict[(i,aas[k],j,aas[l])] += W_pw[k][l][pair_index]  \n",
    "                            \n",
    "                pair_index += 1                    \n",
    "\n",
    "        #print 'Options:',len(pair_dict)\n",
    "        pair_dict = collections.Counter(pair_dict)\n",
    "        pair_dict.most_common()\n",
    "        \n",
    "        # accept highest scoring option\n",
    "        [(k,v)] = pair_dict.most_common(1)\n",
    "        total_score += v\n",
    "        for ind,res in zip([k[0],k[2]],[k[1],k[3]]):\n",
    "            #print 'Adding: {}{}'.format(ind,res)\n",
    "            if not ind in accepted_positions:\n",
    "                accepted_positions.append(ind)\n",
    "                accepted_residues[ind] = res\n",
    "                W_sw[:,ind] = 0\n",
    "        accepted_positions = list(set(accepted_positions))\n",
    "        \n",
    "        print 'Current peptide: {}'.format(''.join(accepted_residues))\n",
    "    print 'Total score:',total_score\n",
    "        #print accepted_positions\n",
    "        \n",
    "        \n",
    "\n",
    "    '''\n",
    "    # merge sw matrix into pw matrix\n",
    "    pair_index = 0\n",
    "    for i in xrange(W_sw.shape[1]):\n",
    "        for j in xrange(i+1,W_sw.shape[1]):\n",
    "            inds = np.unravel_index(W_pw_score[:,:,pair_index].argmax(),W_pw_score[:,:,pair_index].shape)\n",
    "            print '{} : {}{} (Score - {})'.format((i+1,j+1),aas[inds[0]],aas[inds[1]],W_pw_score[inds[0],inds[1],pair_index])\n",
    "            pair_index += 1\n",
    "    '''        \n",
    "            \n",
    "                                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.pcolor(W_sw)\n",
    "    #plt.colorbar()\n",
    "    #plt.show()\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 14)\n"
     ]
    }
   ],
   "source": [
    "print W_sw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
